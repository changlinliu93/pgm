{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 491 Assignment 1 {-}\n",
    "\n",
    "Due Fri Feb 1 before midnight. 100 points total. (Note: the new due date differs from the syllabus, so that you have a full two weeks.)\n",
    "\n",
    "### Submitting assignments to Canvas {-}\n",
    "\n",
    "- For jupyter notebooks, submit the .ipynb file and a pdf export of the notebook.  Make sure the pdf represents the latest state of your notebook.  If your are not using notebooks, writeup your assignment using latex and submit a pdf with your code.  The writeup should include relevant code with description if it can fit on a page.  Do not include binaries or large data files.\n",
    "\n",
    "- Use the following format for filenames:\n",
    "  - `EECS491-A1-yourcaseid.ipynb`\n",
    "  - `EECS491-A1-yourcaseid.pdf`\n",
    "\n",
    "- If you have more than these two files, put all your files in a directory named `EECS491-A1-yourcaseid`. Then zip the directory and submit it with the name `EECS491-A1-yourcaseid.zip`.  Do not use other compression formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of questions below aren't specified in great detail and you may need to spend sometime making sense of the questions themselves, which you can do from the reads and other sources.  You also might need to fill in some blanks or make some assumptions.  The spirit behind this approach is explained in [The Problem with Problems](http://web.mit.edu/6.969/www/readings/mazur.pdf) by Eric Mazur, which I encourage everyone to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Basic probability (10 pts) {-}\n",
    "\n",
    "1.1. Prove (5 pts)\n",
    "$$ p(x,y|z) = p(x|z)p(y|x,z) $$\n",
    "\n",
    "proof:\n",
    "$$ LHS = \\frac{p(x,y,z)}{p(z)}$$\n",
    "$$ RHS = \\frac{p(x,z)}{p(z)}\\cdot\\frac{p(x,y,z)}{p(x,z)} = LHS$$\n",
    "\n",
    "1.2. Prove (5 pts)\n",
    "$$ p(x|y,z) = \\frac{p(y|x,z)p(x|z)}{p(y|z)} $$\n",
    "\n",
    "proof:\n",
    "$$ LHS = \\frac{p(x,y,z)}{p(y,z)} $$\n",
    "$$ RHS = \\frac{\\frac{p(x,y,z)}{p(x,z)}\\cdot\\frac{p(x,z)}{p(z)}}{\\frac{p(y,z)}{p(z)}} = LHS$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Independence (10 pts) {-}\n",
    "\n",
    "2.1 Show that independence is not transitive, i.e. \n",
    "$a \\perp b \\wedge b \\perp c \\nRightarrow a \\perp c$. Define a joint probability distribution $p(a,b,c)$ for which the previous expression holds and provide an interpretation. (5 pts)\n",
    "\n",
    "suppose a,b and c are binary. We have $p(b = 0) = 0.2$, $p(b = 1) = 0.8$ and\n",
    "$$p(a = 0, c = 0) = 0.6$$\n",
    "$$p(a = 1, c = 0) = 0.1$$\n",
    "$$p(a = 0, c = 1) = 0.2$$\n",
    "$$p(a = 1, c = 1) = 0.1$$.\n",
    "\n",
    "It's obvious that the joint probability of $p(a,b,c) = p(b)p(a,c)$ gives independence between b and a or c. However, since\n",
    "$$p(a = 0) = 0.8$$\n",
    "$$p(a = 1) = 0.2$$\n",
    "$$p(c = 0) = 0.7$$\n",
    "$$p(c = 1) = 0.3$$\n",
    "\n",
    "$$p(a = 0) \\cdot p(c = 0) = 0.56 \\neq p(a = 0,c = 0)=0.6$$\n",
    "\n",
    "2.2 Show that conditional independence does not imply marginal independence, i.e. $a \\perp b | c \\nRightarrow a \\perp b$. Again provide an example. (5 pts)\n",
    "\n",
    "We can construct a counter example:\n",
    "\n",
    "Let $p(a = 1) = 0.4$, $p(b = 1) = 0.3$ and $p(c = 1) = 0.5$.\n",
    "We have a joint probability dstribution of a,b and c:\n",
    "\n",
    "$$p(a = 0, b = 0, c = 1) = 0.21$$\n",
    "$$p(a = 0, b = 1, c = 1) = 0.09$$\n",
    "$$p(a = 1, b = 0, c = 1) = 0.14$$\n",
    "$$p(a = 1, b = 1, c = 1) = 0.06$$\n",
    "\n",
    "$$p(a = 0, b = 0, c = 0) = 0.20$$\n",
    "$$p(a = 0, b = 1, c = 0) = 0.10$$\n",
    "$$p(a = 1, b = 0, c = 0) = 0.15$$\n",
    "$$p(a = 1, b = 1, c = 0) = 0.05$$.\n",
    "\n",
    "In this case, $a \\perp b | c=1$ but a and b are not marginally indepentent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Inspector Clouseau re-revisited (20 pts) {-}\n",
    "\n",
    "3.1 Write a program to evaluate $p(B|K)$ in Example 1.3 in Barber. Write your code and choose your data representations so that it is easy to use it to solve the remaining questions. Show that it correctly computes the value in the example. (5 pts)\n",
    "\n",
    "3.2 Define a different distribution for $p(K|M,B)$.  Your new distribution should result in the outcome that $p(B|K)$ is either $<0.1$ or $>0.9$, i.e. reasonably strong evidence.  Use the original values of $p(B)$ and $p(M)$ from the example.  Provide (invent) a reasonble justification for the value of each entry in $p(K|M,B)$. (5 pts)\n",
    "\n",
    "3.3 Derive the equation for $p(M|K)$. (5 pts)\n",
    "\n",
    "3.4 Calculate it's value for both the original $p(K|M,B)$ and the one you defined yourself. Is it possible to provide a summary of the main factors that contributed to the value?  Why/Why not?  Explain. (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7281553398058251"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fpB_K(pB,pM,pK_bm,pK_bM,pK_Bm,pK_BM)\n",
    "    pb = 1 - pB\n",
    "    pm = 1 - pM\n",
    "    return pB*(pK_BM*pM+pK_Bm*pm)/(pb*(pK_bm*pm+pK_bM*pM)+pB*(pK_Bm*pm+pK_BM*pM))\n",
    "end\n",
    "\n",
    "pB = 0.6\n",
    "pM = 0.2\n",
    "\n",
    "pK_bm = 0.3\n",
    "pK_bM = 0.2\n",
    "pK_Bm = 0.6\n",
    "pK_BM = 0.1\n",
    "\n",
    "\n",
    "fpB_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution 3.2\n",
    "\n",
    "If we give very high values for $p(K|B,*)$, the posterior will be very high and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310344827586207"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pB = 0.6\n",
    "pM = 0.2\n",
    "\n",
    "pK_bm = 0.1\n",
    "pK_bM = 0.1\n",
    "pK_Bm = 0.9\n",
    "pK_BM = 0.9\n",
    "\n",
    "\n",
    "fpB_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07317073170731708"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pB = 0.6\n",
    "pM = 0.2\n",
    "\n",
    "pK_bm = 0.95\n",
    "pK_bM = 0.95\n",
    "pK_Bm = 0.05\n",
    "pK_BM = 0.05\n",
    "\n",
    "\n",
    "fpB_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution 3.3\n",
    "\n",
    "$B$ and $M$ are symmetric.\n",
    "$$ p(M|K) = \\frac{p(M)\\sum_{b}p(K|b,M)p(b)}{\\sum_{m}p(m)\\sum_{b}p(K|b,m)p(b)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06796116504854369"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fpM_K(pB,pM,pK_bm,pK_bM,pK_Bm,pK_BM)\n",
    "    pb = 1 - pB\n",
    "    pm = 1 - pM\n",
    "    return pM*(pK_bM*pb+pK_BM*pB)/(pm*(pK_bm*pb+pK_Bm*pB)+pM*(pK_BM*pB+pK_bM*pb))\n",
    "end\n",
    "\n",
    "pB = 0.6\n",
    "pM = 0.2\n",
    "\n",
    "pK_bm = 0.3\n",
    "pK_bM = 0.2\n",
    "pK_Bm = 0.6\n",
    "pK_BM = 0.1\n",
    "\n",
    "\n",
    "fpM_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pK_bm = 0.1\n",
    "pK_bM = 0.1\n",
    "pK_Bm = 0.9\n",
    "pK_BM = 0.9\n",
    "\n",
    "fpM_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pK_bm = 0.95\n",
    "pK_bM = 0.95\n",
    "pK_Bm = 0.05\n",
    "pK_BM = 0.05\n",
    "\n",
    "fpM_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assign high values for $p(K|*,M)$, the response will be higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pK_bm = 0.1\n",
    "pK_bM = 0.9\n",
    "pK_Bm = 0.1\n",
    "pK_BM = 0.9\n",
    "\n",
    "fpM_K(pB, pM, pK_bm, pK_bM, pK_Bm, pK_BM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $p(B|K)$, the main factors are $p(B)$ and $p(K|B,*)$. The same follows when comes to $p(M|K)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Biased views (20 pts) {-}\n",
    "\n",
    "4.1 Write a program that calculates the posterior distribution of the $\\theta$ (probability of heads) from the Binomial distribution given $y$ heads out of $n$ trials.  Feel to use a package where the necessary distributions are defined as primitives. (5 pts)\n",
    "\n",
    "4.2 Imagine three different views on the coin bias:\n",
    "- \"I believe strongly that the coin is biased to either mostly heads or mostly tails.\"\n",
    "- \"I believe strongly that the coin is unbiased\".\n",
    "- \"I don't know anything about the bias of the coin.\"\n",
    "Define and plot prior distributions that expresses each of these beliefs.  Provide a brief explanation. (5 pts)\n",
    "\n",
    "4.3 Perform Bernoulli trials where one of these views is correct.  Show how the posterior distribution of $\\theta$ changes for each view for $n=0, 1, 2, 5, 10, \\textrm{and} 100$.  Each view should have its own plot, with the plots of the posterior after different numbers of trials overlayed. (5 pts)\n",
    "\n",
    "4.4 Is it possible that each view will always arrive at an accurate estimate of $\\theta$?  How might you determine which view is most consistent with the data after $n$ trials? (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Inference using the Poisson distribution (20 pts) {-}\n",
    "\n",
    "Suppose you are observing a series of events that occur at the following times (in seconds): 0.53, 0.65, 0.91, 1.19, 1.30, 1.33, 1.90, 2.01, 2.48.\n",
    "\n",
    "5.1 Model the rate at which the events are produced using a Poisson distribution where $\\lambda$ is the number of events $n$ observed per unit time (1 second).  Show the likelihood equation and plot it for three different values of $\\lambda$: less, about equal, and greater than what you estimate (intuitively) from the data. (5 pts)\n",
    "\n",
    "5.2 Derive the posterior distribution of $\\lambda$ assuming a Gamma prior (usually defined with parameters $\\alpha$ and $\\beta$).  The posterior should have the form $p(\\lambda | n, T, \\alpha, \\beta)$ where $T$ is the total duration of the observation period and $n$ is the number of events observed within that period. (5 pts)\n",
    "\n",
    "5.3 Show that the Gamma distribution is a *conjugate prior* for the Poisson distribution, i.e. it is also a Gamma distribution, but defined by parameters $\\alpha'$ and $\\beta'$ that are functions of the prior and likelihood parameters. (5 pts)\n",
    "\n",
    "5.4 Plot the posterior distribution for the data above at times $T$ = 0, 0.5, and 1.5.  Overlay the curves on a single plot.  Comment how it is possible for your beliefs to change even though no new events have been observed. (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Exploration (20 pts) {-}\n",
    "\n",
    "In these problems, you are meant to do creative exploration.  Define and explore a:\n",
    "\n",
    "6.1 discrete inference problem (10 pts)\n",
    "\n",
    "6.2 continuous inference problem (10 pts)\n",
    "\n",
    "This is meant to be open-ended; you should not feel the need to write a book chapter; but neither should you just change the numbers in one of the problems above.  After doing the readings and problems above, you should pick a concept you want to understand better or an simple modeling idea you want to try out.  The general idea is for you to teaching yourself (and potentially a classate) about something.  You don't necessarily have to know what that is when you start, but you should be able to express what you learned.\n",
    "\n",
    "Here is the grading rubric:\n",
    "- Were the problem clearly described and concise? (3 pts)\n",
    "- Were the relevant concepts clearly explained? (3 pts)\n",
    "- Did the problem go beyond or is distinct from what was already convered in the questions above? (4 pts)\n",
    "\n",
    "You can use the readings and other sources for inspiration, but here are a few ideas:\n",
    "- An inference problem using categorical data\n",
    "- A disease for which there are two different tests\n",
    "- A two-dimensional continuous inference problem\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "latex_metadata": {
   "affiliation": "Case Western Reserve University",
   "author": "Michael S. Lewicki",
   "title": "EECS 491 Spring 2019 Assignment 1 (A1)"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
