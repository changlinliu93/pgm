{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell Checking\n",
    "\n",
    "Spell checking problem cab be solved with bayesian theory. The problem we need to solve is:\n",
    "\n",
    "$$argmax_{correct\\ word}(P(correct\\ word\\ |\\ wrong\\ word) = \\frac{P(wrong\\ word\\ |\\ correct\\ word)P(correct\\ word)}{P(wrong\\ word)})$$\n",
    "\n",
    "$P(wrong\\ word\\ |\\ correct\\ word)$ can be measured with edit distance. $P(correct\\ word)$ is the overall word frequency. We can download a corpus to obtain the word frequency. The denominator is just a scaling factor.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining P(correct word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text): return re.findall('[a-z]+', text.lower())\n",
    "words = get_words(open('corpus.txt').read())\n",
    "frequency = collections.Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining P(wrong word | correct word)\n",
    "\n",
    "For simplicity, we only consider the wrong spellings 1 and 2 edit distance away from the correct spelling. We consider 4 types of mistake - deletion, transpose, replacement and insertion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "def edits1(word):\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    #delete one character\n",
    "    deletes = [a + b[1:] for a, b in splits if b]\n",
    "    #exchange two consecutive characters\n",
    "    transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "    #change one character to another\n",
    "    replaces = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "    #insert one character\n",
    "    inserts = [a + c + b for a, b in splits for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 10 misspellings of 'word':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wcord',\n",
       " 'world',\n",
       " 'wurd',\n",
       " 'wxrd',\n",
       " 'wmord',\n",
       " 'wogrd',\n",
       " 'wori',\n",
       " 'wordm',\n",
       " 'wod',\n",
       " 'ward']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(edits1('word'))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that some are not real English words. We can consider only those in the frequency table and discard the rest of them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cord',\n",
       " 'ford',\n",
       " 'lord',\n",
       " 'ord',\n",
       " 'sword',\n",
       " 'ward',\n",
       " 'wood',\n",
       " 'word',\n",
       " 'words',\n",
       " 'wordy',\n",
       " 'wore',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worm',\n",
       " 'worn'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def known(words): return set(w for w in words if w in frequency)\n",
    "known(edits1('word'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the edits that are 2 edit distance away, we can take those one edit distance away and edit them once more.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world',\n",
       " 'god',\n",
       " 'ward',\n",
       " 'wards',\n",
       " 'worn',\n",
       " 'wound',\n",
       " 'tore',\n",
       " 'cord',\n",
       " 'words',\n",
       " 'woof']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in frequency)\n",
    "list(known_edits2('word'))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Now we have all we need. The candidates for spell correction are chose with a priority:\n",
    "- The original word, if it is known\n",
    "- The list of known words one edit distance away\n",
    "- The list of known words two edit distance away\n",
    "- The original word\n",
    "\n",
    "For candidates of the same priority, we choose the one with highest word frequency as the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word):\n",
    "    return known([word]) or known(edits1(word)) or known_edits2(word) or word\n",
    "\n",
    "def correct(word):\n",
    "    return max(candidates(word), key=lambda x:frequency[x] if not frequency[x] is None else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'al', 'all', 'awl', 'col', 'gaol', 'sol', 'vol'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('aol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('aol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EECS'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('EECS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probability'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('probablity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probability'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('probablity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hale', 'half', 'hall', 'halo', 'halt', 'harp', 'hasp', 'help'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('halp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'half'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('halp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a need some half'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence = lambda sentence:' '.join(map(correct,sentence[:-1].split(' ')))\n",
    "correct_sentence('I need somee halp!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he rates the assignment'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence('He hates the asignments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can see our model can correct spellings, but it's rather naive. It doesn't take context and inflection into consideration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
